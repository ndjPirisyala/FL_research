{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started in Python and NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by typing a couple of examples of arithmetic into the Python interpreter. For example:\n",
    "<br>```>>>1 + 2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you want to type in a string of text, you surround the string with quotes.\n",
    "<br>```>>> ‘hello’ ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hello\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In programming, when we have a value of some type (like the number 3 or the string\n",
    "‘hello’), we can save that value by assigning it to a variable.\n",
    "<br> ```>>> num = 1 + 2 ```\n",
    "<br> ``` >>> num ```\n",
    "<br>In this example, the name of the variable is “num” and its value is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 1 + 2\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you use the Python “import” statement to load the data used in the book examples\n",
    "into the Python environment:\n",
    "<br> ``` >>> from nltk.book import * ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command loaded 9 of the text examples available from the corpora package (only a\n",
    "small number of them!). It has used the variable names text1 through text9 for these\n",
    "examples, and already assigned them values. If you type the variable name, you get a\n",
    "description of the text:\n",
    "<br> ``` >>> text1 ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables sent1 through sent9 have been set to be a list of tokens of the first sentence\n",
    "of each text.\n",
    "<br> ``` >>> sent1 ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data structure has a number of functions to operate on text. One is called\n",
    "“concordance”, and it will search for any word that you give to the function and show you\n",
    "the occurrences and some surrounding context.\n",
    "<br> ``` >>> text1.concordance(\"monstrous\") ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the use of the arrow keys with the enter key to select and modify previous lines in\n",
    "Python, and try a similar example.\n",
    "<br> ``` >>> text2.concordance(\"affection\") ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 79 matches:\n",
      ", however , and , as a mark of his affection for the three girls , he left them\n",
      "t . It was very well known that no affection was ever supposed to exist between\n",
      "deration of politeness or maternal affection on the side of the former , the tw\n",
      "d the suspicion -- the hope of his affection for me may warrant , without impru\n",
      "hich forbade the indulgence of his affection . She knew that his mother neither\n",
      "rd she gave one with still greater affection . Though her late conversation wit\n",
      " can never hope to feel or inspire affection again , and if her home be uncomfo\n",
      "m of the sense , elegance , mutual affection , and domestic comfort of the fami\n",
      ", and which recommended him to her affection beyond every thing else . His soci\n",
      "ween the parties might forward the affection of Mr . Willoughby , an equally st\n",
      " the most pointed assurance of her affection . Elinor could not be surprised at\n",
      "he natural consequence of a strong affection in a young and ardent mind . This \n",
      " opinion . But by an appeal to her affection for her mother , by representing t\n",
      " every alteration of a place which affection had established as perfect with hi\n",
      "e will always have one claim of my affection , which no other can possibly shar\n",
      "f the evening declared at once his affection and happiness . \" Shall we see you\n",
      "ause he took leave of us with less affection than his usual behaviour has shewn\n",
      "ness .\" \" I want no proof of their affection ,\" said Elinor ; \" but of their en\n",
      "onths , without telling her of his affection ;-- that they should part without \n",
      "ould be the natural result of your affection for her . She used to be all unres\n",
      "distinguished Elinor by no mark of affection . Marianne saw and listened with i\n",
      "th no inclination for expense , no affection for strangers , no profession , an\n",
      "till distinguished her by the same affection which once she had felt no doubt o\n",
      "al of her confidence in Edward ' s affection , to the remembrance of every mark\n",
      " was made ? Had he never owned his affection to yourself ?\" \" Oh , no ; but if \n"
     ]
    }
   ],
   "source": [
    "text2.concordance(\"affection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another function is “similar” which finds all the words that are used in the same context as\n",
    "the one given, where the context is the word before and the word after.\n",
    "<br> ``` >>> text1.similar(\"monstrous\") ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to compare how the same word is used differently in other texts.\n",
    "<br> ``` >>> text2.similar(\"monstrous\") ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each text from the books was separated into a list of tokens, and this is one of the first NLP\n",
    "processing steps. The tokens usually consist of words and all the punctuation and other\n",
    "symbols occurring in the text. To further investigate text, we can count the occurrences of\n",
    "words.\n",
    "We start by using the Python length function, “len” to tell us how many things are in a list.\n",
    "(Strictly speaking, each text variable is an object of type nltk.text.Text, which contains the\n",
    "text string and some other functions, but we’re trying not to explain much programming\n",
    "here.)\n",
    "<br> ``` >>> len(text3) ```\n",
    "<br> ``` >>> len(text4) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149797"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is the total number of tokens, and we might also want to find out how many\n",
    "unique words there are, not counting repetitions. The Python “set” function removes the\n",
    "repetitions, and we can apply the “sorted” function to that, returning the resulted sorted\n",
    "list of tokens. If we type the following, lots of words will flash by on the screen.\n",
    "<br> ``` >>> sorted(set(text3)) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can just find the length of that list.\n",
    "<br> ``` >>> len(sorted(set(text3))) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(set(text3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can specify just to print the first 30 words in the list of sorted words:\n",
    "<br> ``` >>> sorted(set(text3))[:30] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s compute the ratio of the total number of tokens to the number of unique tokens\n",
    "and we’ll get an average of how many repetitions there are for each word. First we get a\n",
    "division operator that uses real arithmetic (aka floating point) instead of integer and then\n",
    "we divide to get the ratio.\n",
    "<br> ``` >>> from __future__ import division ```\n",
    "<br> ``` >>> len(text3) / len(set(text3) ``` <br>\n",
    "(On average, each word is used about 16 times.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.050197203298673"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3) / len(set(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s search for and count occurrences of particular words and compare that to the\n",
    "total number of words.\n",
    "<br> ``` >>> text3.count(\"smote\") ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the fraction of the number of occurrences of the word compared with the total\n",
    "number of words and then multiply by 100 to get a percentage.\n",
    "<br> ``` >>> 100 * text3.count('smote') / len(text3) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01116968992940756"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text3.count('smote') / len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare with a more common word, such as the word “a”?\n",
    "<br> ``` >>> 100 * text3.count('a') / len(text3)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7640067911714771"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text3.count('a') / len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it Out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many times does the word “lol” occur in text5? What is the percentage of its\n",
    "occurrences in the text? [Warning: text5 is uncensored chat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many times does the word “lol” occur in text5\n",
    "text5.count(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5640968673628082"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the percentage of its occurrences in the text\n",
    "100 * (text5.count(\"lol\") / len(text5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of another word to find occurrences and get the number of occurrences and its\n",
    "percentage in the text. Save the word, the number of occurrences and its percentage in the\n",
    "text to post at the end of class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "0.019995556542990445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = text5.count(\"book\")\n",
    "print(num)\n",
    "pre =  100 * (text5.count(\"book\") / len(text5))\n",
    "print(pre)\n",
    "\n",
    "open('result.txt','w').write('Number of time that word \\\"book\\\" has appeared {} , percentage {}%'.format(num,pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this lab, we counted words from text that had already been tokenized, i.e.\n",
    "separated into words. Now we’ll look at some text examples that we will need to tokenize.\n",
    "In addition to the examples that we imported for the NLTK book above, the NLTK has a\n",
    "number of other corpora, described in Chapter 2. In order to see these, type in\n",
    "\n",
    "<br> ``` >>> import nltk ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then view some books obtained from the Gutenberg on---line book project:\n",
    "<br> ``` >>> nltk.corpus.gutenberg.fileids() ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of this lab, we will work with the first book, Jane Austen’s “Emma”. First, we\n",
    "save the first fileid (number 0 in the list) into a variable named file1 so that we can reuse it:\n",
    "<br> ``` >>> file1 = nltk.corpus.gutenberg.fileids( ) [0] ```\n",
    "<br> ``` >>> file1 ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = nltk.corpus.gutenberg.fileids( ) [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'austen-emma.txt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the original text, using the raw function:\n",
    "<br> ``` >>> emmatext = nltk.corpus.gutenberg.raw(file1) ```\n",
    "<br> ``` >>> len(emmatext) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmatext = nltk.corpus.gutenberg.raw(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887071"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emmatext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is quite long, we can view part of it, e.g. the first 120 characters\n",
    "<br> ``` >>> emmatext[:120] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nan'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmatext[:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK has several tokenizers available to break the raw text into tokens; we will use one\n",
    "that separates by white space and also by special characters (punctuation):\n",
    "<br> ``` >>> emmatokens = nltk.wordpunct_tokenize(emmatext) ```\n",
    "<br> ``` >>> len(emmatokens) ```\n",
    "<br> ``` >>> emmatokens[:50] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmatokens = nltk.wordpunct_tokenize(emmatext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emmatokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Emma',\n",
       " 'by',\n",
       " 'Jane',\n",
       " 'Austen',\n",
       " '1816',\n",
       " ']',\n",
       " 'VOLUME',\n",
       " 'I',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " 'Emma',\n",
       " 'Woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'comfortable',\n",
       " 'home',\n",
       " 'and',\n",
       " 'happy',\n",
       " 'disposition',\n",
       " ',',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'unite',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'best',\n",
       " 'blessings',\n",
       " 'of',\n",
       " 'existence',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " 'lived',\n",
       " 'nearly',\n",
       " 'twenty',\n",
       " '-',\n",
       " 'one',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmatokens[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably want to use the lowercase versions of the words:\n",
    "<br> ``` >>> emmawords = [w.lower( ) for w in emmatokens] ```\n",
    "<br> ``` >>> emmawords[:50] ```\n",
    "<br> ``` >>> len(emmawords) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmawords = [w.lower( ) for w in emmatokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'emma',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " '1816',\n",
       " ']',\n",
       " 'volume',\n",
       " 'i',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'emma',\n",
       " 'woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'comfortable',\n",
       " 'home',\n",
       " 'and',\n",
       " 'happy',\n",
       " 'disposition',\n",
       " ',',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'unite',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'best',\n",
       " 'blessings',\n",
       " 'of',\n",
       " 'existence',\n",
       " ';',\n",
       " 'and',\n",
       " 'had',\n",
       " 'lived',\n",
       " 'nearly',\n",
       " 'twenty',\n",
       " '-',\n",
       " 'one',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmawords[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emmawords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further view the words by getting the unique words and sorting them:\n",
    "<br> ``` >>> emmavocab = sorted(set(emmawords))```\n",
    "<br> ``` >>> emmavocab[:50]```\n",
    "<br>\n",
    "\n",
    "We can see that we will probably want to get rid of these special characters – Regular\n",
    "Expressions to the Rescue! (as in xkcd _ ), but we’ll work on that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmavocab = sorted(set(emmawords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '!\"',\n",
       " '!\"--',\n",
       " \"!'\",\n",
       " \"!'--\",\n",
       " '!)--',\n",
       " '!--',\n",
       " '!--\"',\n",
       " '!--(',\n",
       " '!--`',\n",
       " '\"',\n",
       " '\"\\'',\n",
       " '\"--',\n",
       " '\"`',\n",
       " '&',\n",
       " \"'\",\n",
       " \"'--\",\n",
       " \"';\",\n",
       " '(',\n",
       " ')',\n",
       " '),',\n",
       " ')--',\n",
       " ').',\n",
       " ').--',\n",
       " ');--',\n",
       " ',',\n",
       " ',\"',\n",
       " ',\"--',\n",
       " \",'\",\n",
       " ',\\'\"',\n",
       " ',)',\n",
       " ',--',\n",
       " ',--\"',\n",
       " '-',\n",
       " '--',\n",
       " '--\"',\n",
       " '--(',\n",
       " '--,',\n",
       " '----',\n",
       " '----------,',\n",
       " \"--------.'\",\n",
       " '--.',\n",
       " '--.\"',\n",
       " \"--.'\",\n",
       " '--:',\n",
       " '--`',\n",
       " '.',\n",
       " '.\"',\n",
       " '.\"--',\n",
       " \".'\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emmavocab[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
