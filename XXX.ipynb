{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random \n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import nest_asyncio\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "sns.set_theme(style= 'whitegrid')\n",
    "nest_asyncio.apply()\n",
    "tff.backends.reference.set_reference_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, choice, shuffle\n",
    "from math import ceil\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIENT1, CLIENT2, CLIENT3, CLIENT4, CLIENT5, CLIENT6, CLIENT7, CLIENT8, CLIENT9, CLIENT10,= clientDATA(10,data).values()\n",
    "# DIM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIENT1, CLIENT2, CLIENT3, CLIENT4, CLIENT5, CLIENT6, CLIENT7, CLIENT8, CLIENT9, CLIENT10,= createClients()\n",
    "# DIM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIENT1, CLIENT2, CLIENT3, CLIENT4, CLIENT5, CLIENT6, CLIENT7, CLIENT8, CLIENT9, CLIENT10,= newDATA(data)\n",
    "# DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT1, CLIENT2, CLIENT3, CLIENT4, CLIENT5, CLIENT6, CLIENT7, CLIENT8, CLIENT9, CLIENT10,= createClientsDATA(data)\n",
    "DIM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(HOLDER):\n",
    "    federated_data = []\n",
    "    for i in HOLDER:\n",
    "        client = []\n",
    "        for index in range(len(i)//100):\n",
    "            X= []\n",
    "            Y= []\n",
    "            for elements in i[index*100:index*100+100]:\n",
    "                X.append(np.array([np.float32(elements[0]/10000),\n",
    "                                   np.float32(elements[1]/10000),\n",
    "                                   np.float32(elements[2]/10000),\n",
    "                                   np.float32(elements[3]/10000),\n",
    "                                   np.float32(elements[4]/10000),\n",
    "                                   np.float32(elements[5]/10000),\n",
    "                                   np.float32(elements[6]/10000),\n",
    "                                   np.float32(elements[7]/10000),\n",
    "                                   np.float32(elements[8]/10000),\n",
    "                                   np.float32(elements[9]/10000),\n",
    "                                  ]))\n",
    "                Y.append(np.array(np.int32(elements[10])))\n",
    "            client.append({\n",
    "                'x':np.array(X),\n",
    "                'y':np.array(Y)\n",
    "            })\n",
    "        federated_data.append(client)\n",
    "    return federated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poissonDistributiondata(clientData):\n",
    "    data = random.sample(clientData,2000)\n",
    "    return [data[:1000],data[1000:1500],data[1500:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reselectClientData():\n",
    "    c1_tra, c1_val, c1_test = poissonDistributiondata(CLIENT1)\n",
    "    c2_tra, c2_val, c2_test = poissonDistributiondata(CLIENT2)\n",
    "    c3_tra, c3_val, c3_test = poissonDistributiondata(CLIENT3)\n",
    "    c4_tra, c4_val, c4_test = poissonDistributiondata(CLIENT4)\n",
    "    c5_tra, c5_val, c5_test = poissonDistributiondata(CLIENT5)\n",
    "    c6_tra, c6_val, c6_test = poissonDistributiondata(CLIENT6)\n",
    "    c7_tra, c7_val, c7_test = poissonDistributiondata(CLIENT7)\n",
    "    c8_tra, c8_val, c8_test = poissonDistributiondata(CLIENT8)\n",
    "    c9_tra, c9_val, c9_test = poissonDistributiondata(CLIENT9)\n",
    "    c10_tra, c10_val, c10_test = poissonDistributiondata(CLIENT10)\n",
    "\n",
    "    train = [c1_tra,   c2_tra,  c3_tra, c4_tra,   c5_tra,  c6_tra, c7_tra,   c8_tra,  c9_tra, c10_tra]\n",
    "    val   = [c1_val,   c2_val,  c3_val, c4_val,   c5_val,  c6_val, c7_val,   c8_val,  c9_val, c10_val]\n",
    "    test  = [c1_test,  c2_test, c3_test, c4_test, c5_test, c6_test, c7_test, c8_test, c9_test, c10_test]\n",
    "\n",
    "    federated_train_data      =  get_batches(train)\n",
    "    federated_validation_data =  get_batches(val)\n",
    "    federated_test_data       =  get_batches(test)\n",
    "    \n",
    "    #count\n",
    "    ARR.append([Counter(list(map(lambda x: x[-1], c1_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c2_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c3_tra))),\n",
    "                Counter(list(map(lambda x: x[-1], c4_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c5_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c6_tra))),\n",
    "                Counter(list(map(lambda x: x[-1], c7_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c8_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c9_tra))),\n",
    "                Counter(list(map(lambda x: x[-1], c10_tra)))])\n",
    "    #mean\n",
    "    \n",
    "    return (federated_train_data,federated_validation_data,federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "if all([None]) : \n",
    "    print(1)\n",
    "else:\n",
    "    print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(arr_history):\n",
    "    client1_means  = [i[0] for i in arr_history]\n",
    "    client2_means  = [i[1] for i in arr_history]\n",
    "    client3_means  = [i[2] for i in arr_history]\n",
    "    client4_means  = [i[3] for i in arr_history]\n",
    "    client5_means  = [i[4] for i in arr_history]\n",
    "    client6_means  = [i[5] for i in arr_history]\n",
    "    client7_means  = [i[6] for i in arr_history]\n",
    "    client8_means  = [i[7] for i in arr_history]\n",
    "    client9_means  = [i[8] for i in arr_history]\n",
    "    client10_means = [i[9] for i in arr_history]\n",
    "    \n",
    "    client1_means_vals_c1 = [0]\n",
    "    client1_means_vals_c2 = [0]    \n",
    "    client1_means_vals_c3 = [0]\n",
    "    client1_means_vals_c4 = [0]    \n",
    "    client1_means_vals_c5 = [0] \n",
    "    \n",
    "    client2_means_vals_c1 = [0]\n",
    "    client2_means_vals_c2 = [0]    \n",
    "    client2_means_vals_c3 = [0]\n",
    "    client2_means_vals_c4 = [0]    \n",
    "    client2_means_vals_c5 = [0] \n",
    "    \n",
    "    client3_means_vals_c1 = [0]\n",
    "    client3_means_vals_c2 = [0]    \n",
    "    client3_means_vals_c3 = [0]\n",
    "    client3_means_vals_c4 = [0]    \n",
    "    client3_means_vals_c5 = [0]\n",
    "    \n",
    "    client4_means_vals_c1 = [0]\n",
    "    client4_means_vals_c2 = [0]    \n",
    "    client4_means_vals_c3 = [0]\n",
    "    client4_means_vals_c4 = [0]    \n",
    "    client4_means_vals_c5 = [0] \n",
    "    \n",
    "    client5_means_vals_c1 = [0]\n",
    "    client5_means_vals_c2 = [0]    \n",
    "    client5_means_vals_c3 = [0]\n",
    "    client5_means_vals_c4 = [0]    \n",
    "    client5_means_vals_c5 = [0] \n",
    "    \n",
    "    client6_means_vals_c1 = [0]\n",
    "    client6_means_vals_c2 = [0]    \n",
    "    client6_means_vals_c3 = [0]\n",
    "    client6_means_vals_c4 = [0]    \n",
    "    client6_means_vals_c5 = [0]\n",
    "    \n",
    "    client7_means_vals_c1 = [0]\n",
    "    client7_means_vals_c2 = [0]    \n",
    "    client7_means_vals_c3 = [0]\n",
    "    client7_means_vals_c4 = [0]    \n",
    "    client7_means_vals_c5 = [0]\n",
    "    \n",
    "    client8_means_vals_c1 = [0]\n",
    "    client8_means_vals_c2 = [0]    \n",
    "    client8_means_vals_c3 = [0]\n",
    "    client8_means_vals_c4 = [0]    \n",
    "    client8_means_vals_c5 = [0]\n",
    "    \n",
    "    client9_means_vals_c1 = [0]\n",
    "    client9_means_vals_c2 = [0]    \n",
    "    client9_means_vals_c3 = [0]\n",
    "    client9_means_vals_c4 = [0]    \n",
    "    client9_means_vals_c5 = [0]\n",
    "    \n",
    "    client10_means_vals_c1 = [0]\n",
    "    client10_means_vals_c2 = [0]    \n",
    "    client10_means_vals_c3 = [0]\n",
    "    client10_means_vals_c4 = [0]    \n",
    "    client10_means_vals_c5 = [0]\n",
    "    \n",
    "    client1_means_vals_c1 = [i.get(0) for i in client1_means]\n",
    "    client1_means_vals_c2 = [i.get(1) for i in client1_means]    \n",
    "    client1_means_vals_c3 = [i.get(2) for i in client1_means]\n",
    "    client1_means_vals_c4 = [i.get(3) for i in client1_means]    \n",
    "    client1_means_vals_c5 = [i.get(4) for i in client1_means]    \n",
    "    \n",
    "    client2_means_vals_c1 = [i.get(0) for i in client2_means]\n",
    "    client2_means_vals_c2 = [i.get(1) for i in client2_means]    \n",
    "    client2_means_vals_c3 = [i.get(2) for i in client2_means]\n",
    "    client2_means_vals_c4 = [i.get(3) for i in client2_means]    \n",
    "    client1_means_vals_c5 = [i.get(4) for i in client2_means]    \n",
    "    \n",
    "    client3_means_vals_c1 = [i.get(0) for i in client3_means]\n",
    "    client3_means_vals_c2 = [i.get(1) for i in client3_means]    \n",
    "    client3_means_vals_c3 = [i.get(2) for i in client3_means]\n",
    "    client3_means_vals_c4 = [i.get(3) for i in client3_means]    \n",
    "    client3_means_vals_c5 = [i.get(4) for i in client3_means]    \n",
    "    \n",
    "    client4_means_vals_c1 = [i.get(0) for i in client4_means]\n",
    "    client4_means_vals_c2 = [i.get(1) for i in client4_means]    \n",
    "    client4_means_vals_c3 = [i.get(2) for i in client4_means]\n",
    "    client4_means_vals_c4 = [i.get(3) for i in client4_means]    \n",
    "    client4_means_vals_c5 = [i.get(4) for i in client4_means]    \n",
    "    \n",
    "    client5_means_vals_c1 = [i.get(0) for i in client5_means]\n",
    "    client5_means_vals_c2 = [i.get(1) for i in client5_means]    \n",
    "    client5_means_vals_c3 = [i.get(2) for i in client5_means]\n",
    "    client5_means_vals_c4 = [i.get(3) for i in client5_means]    \n",
    "    client5_means_vals_c5 = [i.get(4) for i in client5_means]    \n",
    "    \n",
    "    client6_means_vals_c1 = [i.get(0) for i in client6_means]\n",
    "    client6_means_vals_c2 = [i.get(1) for i in client6_means]    \n",
    "    client6_means_vals_c3 = [i.get(2) for i in client6_means]\n",
    "    client6_means_vals_c4 = [i.get(3) for i in client6_means]    \n",
    "    client6_means_vals_c5 = [i.get(4) for i in client6_means] \n",
    "    \n",
    "    client7_means_vals_c1 = [i.get(0) for i in client7_means]\n",
    "    client7_means_vals_c2 = [i.get(1) for i in client7_means]    \n",
    "    client7_means_vals_c3 = [i.get(2) for i in client7_means]\n",
    "    client7_means_vals_c4 = [i.get(3) for i in client7_means]    \n",
    "    client7_means_vals_c5 = [i.get(4) for i in client7_means]    \n",
    "    \n",
    "    client8_means_vals_c1 = [i.get(0) for i in client8_means]\n",
    "    client8_means_vals_c2 = [i.get(1) for i in client8_means]    \n",
    "    client8_means_vals_c3 = [i.get(2) for i in client8_means]\n",
    "    client8_means_vals_c4 = [i.get(3) for i in client8_means]    \n",
    "    client8_means_vals_c5 = [i.get(4) for i in client8_means]    \n",
    "    \n",
    "    client9_means_vals_c1 = [i.get(0) for i in client9_means]\n",
    "    client9_means_vals_c2 = [i.get(1) for i in client9_means]    \n",
    "    client9_means_vals_c3 = [i.get(2) for i in client9_means]\n",
    "    client9_means_vals_c4 = [i.get(3) for i in client9_means]    \n",
    "    client9_means_vals_c5 = [i.get(4) for i in client9_means] \n",
    "    \n",
    "    client10_means_vals_c1 = [i.get(0) for i in client10_means]\n",
    "    client10_means_vals_c2 = [i.get(1) for i in client10_means]    \n",
    "    client10_means_vals_c3 = [i.get(2) for i in client10_means]\n",
    "    client10_means_vals_c4 = [i.get(3) for i in client10_means]    \n",
    "    client10_means_vals_c5 = [i.get(4) for i in client10_means]    \n",
    "    \n",
    "    if not all(client1_means_vals_c1) : client1_means_vals_c1 = [0]\n",
    "    if not all(client1_means_vals_c2) : client1_means_vals_c2 = [0]   \n",
    "    if not all(client1_means_vals_c3) : client1_means_vals_c3 = [0] \n",
    "    if not all(client1_means_vals_c4) : client1_means_vals_c4 = [0]  \n",
    "    if not all(client1_means_vals_c5) : client1_means_vals_c5 = [0]     \n",
    "        \n",
    "    if not all(client2_means_vals_c1) : client2_means_vals_c1 = [0]\n",
    "    if not all(client2_means_vals_c2) : client2_means_vals_c2 = [0]   \n",
    "    if not all(client2_means_vals_c3) : client2_means_vals_c3 = [0] \n",
    "    if not all(client2_means_vals_c4) : client2_means_vals_c4 = [0]  \n",
    "    if not all(client2_means_vals_c5) : client2_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client3_means_vals_c1) : client3_means_vals_c1 = [0]\n",
    "    if not all(client3_means_vals_c2) : client3_means_vals_c2 = [0]   \n",
    "    if not all(client3_means_vals_c3) : client3_means_vals_c3 = [0] \n",
    "    if not all(client3_means_vals_c4) : client3_means_vals_c4 = [0]  \n",
    "    if not all(client3_means_vals_c5) : client3_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client4_means_vals_c1) : client4_means_vals_c1 = [0]\n",
    "    if not all(client4_means_vals_c2) : client4_means_vals_c2 = [0]   \n",
    "    if not all(client4_means_vals_c3) : client4_means_vals_c3 = [0] \n",
    "    if not all(client4_means_vals_c4) : client4_means_vals_c4 = [0]  \n",
    "    if not all(client4_means_vals_c5) : client4_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client5_means_vals_c1) : client5_means_vals_c1 = [0]\n",
    "    if not all(client5_means_vals_c2) : client5_means_vals_c2 = [0]   \n",
    "    if not all(client5_means_vals_c3) : client5_means_vals_c3 = [0] \n",
    "    if not all(client5_means_vals_c4) : client5_means_vals_c4 = [0]  \n",
    "    if not all(client5_means_vals_c5) : client5_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client6_means_vals_c1) : client6_means_vals_c1 = [0]\n",
    "    if not all(client6_means_vals_c2) : client6_means_vals_c2 = [0]   \n",
    "    if not all(client6_means_vals_c3) : client6_means_vals_c3 = [0] \n",
    "    if not all(client6_means_vals_c4) : client6_means_vals_c4 = [0]  \n",
    "    if not all(client6_means_vals_c5) : client6_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client7_means_vals_c1) : client7_means_vals_c1 = [0]\n",
    "    if not all(client7_means_vals_c2) : client7_means_vals_c2 = [0]   \n",
    "    if not all(client7_means_vals_c3) : client7_means_vals_c3 = [0] \n",
    "    if not all(client7_means_vals_c4) : client7_means_vals_c4 = [0]  \n",
    "    if not all(client7_means_vals_c5) : client7_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client8_means_vals_c1) : client8_means_vals_c1 = [0]\n",
    "    if not all(client8_means_vals_c2) : client8_means_vals_c2 = [0]   \n",
    "    if not all(client8_means_vals_c3) : client8_means_vals_c3 = [0] \n",
    "    if not all(client8_means_vals_c4) : client8_means_vals_c4 = [0]  \n",
    "    if not all(client8_means_vals_c5) : client8_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client9_means_vals_c1) : client9_means_vals_c1 = [0]\n",
    "    if not all(client9_means_vals_c2) : client9_means_vals_c2 = [0]   \n",
    "    if not all(client9_means_vals_c3) : client9_means_vals_c3 = [0] \n",
    "    if not all(client9_means_vals_c4) : client9_means_vals_c4 = [0]  \n",
    "    if not all(client9_means_vals_c5) : client9_means_vals_c5 = [0] \n",
    "        \n",
    "    if not all(client10_means_vals_c1) : client10_means_vals_c1 = [0]\n",
    "    if not all(client10_means_vals_c2) : client10_means_vals_c2 = [0]   \n",
    "    if not all(client10_means_vals_c3) : client10_means_vals_c3 = [0] \n",
    "    if not all(client10_means_vals_c4) : client10_means_vals_c4 = [0]  \n",
    "    if not all(client10_means_vals_c5) : client10_means_vals_c5 = [0] \n",
    "    \n",
    "    return {\n",
    "        'client1':{\n",
    "            0: mean(client1_means_vals_c1),\n",
    "            1: mean(client1_means_vals_c2),\n",
    "            2: mean(client1_means_vals_c3),\n",
    "            3: mean(client1_means_vals_c4),\n",
    "            4: mean(client1_means_vals_c5)\n",
    "        },\n",
    "        'client2':{\n",
    "            0: mean(client2_means_vals_c1),\n",
    "            1: mean(client2_means_vals_c2),\n",
    "            2: mean(client2_means_vals_c3),\n",
    "            3: mean(client2_means_vals_c4),\n",
    "            4: mean(client2_means_vals_c5)\n",
    "        },\n",
    "        'client3':{\n",
    "            0: mean(client3_means_vals_c1),\n",
    "            1: mean(client3_means_vals_c2),\n",
    "            2: mean(client3_means_vals_c3),\n",
    "            3: mean(client3_means_vals_c4),\n",
    "            4: mean(client3_means_vals_c5)\n",
    "        },\n",
    "         'client4':{\n",
    "            0: mean(client4_means_vals_c1),\n",
    "            1: mean(client4_means_vals_c2),\n",
    "            2: mean(client4_means_vals_c3),\n",
    "            3: mean(client4_means_vals_c4),\n",
    "            4: mean(client4_means_vals_c5)\n",
    "        },\n",
    "        'client5':{\n",
    "            0: mean(client5_means_vals_c1),\n",
    "            1: mean(client5_means_vals_c2),\n",
    "            2: mean(client5_means_vals_c3),\n",
    "            3: mean(client5_means_vals_c4),\n",
    "            4: mean(client5_means_vals_c5)\n",
    "        },\n",
    "        'client6':{\n",
    "            0: mean(client6_means_vals_c1),\n",
    "            1: mean(client6_means_vals_c2),\n",
    "            2: mean(client6_means_vals_c3),\n",
    "            3: mean(client6_means_vals_c4),\n",
    "            4: mean(client6_means_vals_c5)\n",
    "        },\n",
    "         'client7':{\n",
    "            0: mean(client7_means_vals_c1),\n",
    "            1: mean(client7_means_vals_c2),\n",
    "            2: mean(client7_means_vals_c3),\n",
    "            3: mean(client7_means_vals_c4),\n",
    "            4: mean(client7_means_vals_c5)\n",
    "        },\n",
    "        'client8':{\n",
    "            0: mean(client8_means_vals_c1),\n",
    "            1: mean(client8_means_vals_c2),\n",
    "            2: mean(client8_means_vals_c3),\n",
    "            3: mean(client8_means_vals_c4),\n",
    "            4: mean(client8_means_vals_c5)\n",
    "        },\n",
    "        'client9':{\n",
    "            0: mean(client9_means_vals_c1),\n",
    "            1: mean(client9_means_vals_c2),\n",
    "            2: mean(client9_means_vals_c3),\n",
    "            3: mean(client9_means_vals_c4),\n",
    "            4: mean(client9_means_vals_c5)\n",
    "        },\n",
    "        'client10':{\n",
    "            0: mean(client10_means_vals_c1),\n",
    "            1: mean(client10_means_vals_c2),\n",
    "            2: mean(client10_means_vals_c3),\n",
    "            3: mean(client10_means_vals_c4),\n",
    "            4: mean(client10_means_vals_c5)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Follow shows the get mean output\n",
    "```get_mean(ARR)```\n",
    "\n",
    "```{'client1': {0: 706.5, 1: 154, 2: 139.5},\n",
    " 'client2': {0: 188, 1: 611, 2: 201},\n",
    " 'client3': {0: 92, 1: 245, 2: 663}}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom mean aggregation function goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGG_FUNCTION1(mean):\n",
    "    return [\n",
    "        np.float32(max(mean.get('client1').values())),\n",
    "        np.float32(max(mean.get('client2').values())),\n",
    "        np.float32(max(mean.get('client3').values())),\n",
    "        np.float32(max(mean.get('client4').values())),\n",
    "        np.float32(max(mean.get('client5').values())),\n",
    "        np.float32(max(mean.get('client6').values())),\n",
    "        np.float32(max(mean.get('client7').values())),\n",
    "        np.float32(max(mean.get('client8').values())),\n",
    "        np.float32(max(mean.get('client9').values())),\n",
    "        np.float32(max(mean.get('client10').values()))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGG_FUNCTION2(mean):\n",
    "    return [\n",
    "        np.float32(min(mean.get('client1').values())),\n",
    "        np.float32(min(mean.get('client2').values())),\n",
    "        np.float32(min(mean.get('client3').values())),\n",
    "        np.float32(min(mean.get('client4').values())),\n",
    "        np.float32(min(mean.get('client5').values())),\n",
    "        np.float32(min(mean.get('client6').values())),\n",
    "        np.float32(min(mean.get('client7').values())),\n",
    "        np.float32(min(mean.get('client8').values())),\n",
    "        np.float32(min(mean.get('client9').values())),\n",
    "        np.float32(min(mean.get('client10').values()))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGG_FUNCTION3(mean):\n",
    "    return [\n",
    "        np.float32(sum(mean.get('client1').values())),\n",
    "        np.float32(sum(mean.get('client2').values())),\n",
    "        np.float32(sum(mean.get('client3').values())),\n",
    "        np.float32(sum(mean.get('client4').values())),\n",
    "        np.float32(sum(mean.get('client5').values())),\n",
    "        np.float32(sum(mean.get('client6').values())),\n",
    "        np.float32(sum(mean.get('client7').values())),\n",
    "        np.float32(sum(mean.get('client8').values())),\n",
    "        np.float32(sum(mean.get('client9').values())),\n",
    "        np.float32(sum(mean.get('client10').values()))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGG_FUNCTION4(mean):\n",
    "    return [\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client1').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client2').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client3').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client4').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client5').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client6').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client7').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client8').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client9').values()))),\n",
    "        np.float32(sum(map(lambda x: x*x ,mean.get('client10').values())))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGG_FUNCTION5(mean):\n",
    "    return [\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client1').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client2').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client3').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client4').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client5').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client6').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client7').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client8').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client9').values())))),\n",
    "        np.float32(sqrt(sum(map(lambda x: x*x ,mean.get('client10').values()))))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGG_FUNCTION6():\n",
    "    return [\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "        np.float32(random.uniform(1.1, 3.61)),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AGG_FUNCTION6())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Data Types [Client and Server]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(x=tf.TensorSpec(shape=[None, 10], dtype=tf.float32),\n",
    "                                     y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "\n",
    "MODEL_SPEC = collections.OrderedDict(weights=tf.TensorSpec(shape=[10, DIM], dtype=tf.float32),\n",
    "                                     bias=tf.TensorSpec(shape=[DIM], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "\n",
    "WEIGHT_SPEC = tff.TensorType(dtype=tf.float32, shape=None)\n",
    "WEIGHT_TYPE = tff.to_type(WEIGHT_SPEC)\n",
    "WEIGHT_DATA_TYPE = tff.FederatedType(WEIGHT_TYPE, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(tf.reduce_sum(tf.one_hot(batch['y'], DIM) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "    return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model_vars, batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "  \n",
    "    return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_fn(model, batch):\n",
    "        return batch_train(model, batch, learning_rate)\n",
    "    return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "    return tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),all_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.type_at_server(MODEL_TYPE)\n",
    "CLIENT_DATA_TYPE = tff.type_at_clients(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "    return tff.federated_mean(tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SERVER_FLOAT_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.type_at_server(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With custom weighting factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,CLIENT_DATA_TYPE, WEIGHT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data, weights):\n",
    "    return tff.federated_mean(\n",
    "          tff.federated_map(local_train, [\n",
    "          tff.federated_broadcast(model),\n",
    "          tff.federated_broadcast(learning_rate), data]), weights)\n",
    "\n",
    "def modelR(weights, biases, data):\n",
    "#     print(weights)\n",
    "#     print(biases)\n",
    "    count = 0\n",
    "    avg = 0\n",
    "    for j in range(len(federated_test_data[0])):\n",
    "        l = [np.where(i==max(i))[0][0] for i in activations.sigmoid(np.matmul(federated_test_data[0][j].get('x'), model.get('weights'))).numpy()]\n",
    "        Y = federated_test_data[0][j].get('y')\n",
    "        \n",
    "        for i in range(len(Y)):\n",
    "            avg+=1\n",
    "            if l[i] == Y[i]:\n",
    "                count+= 1\n",
    "                \n",
    "    return count/avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without custom weighting factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,CLIENT_DATA_TYPE)\n",
    "def federated_train_2(model, learning_rate, data):\n",
    "    return tff.federated_mean(\n",
    "          tff.federated_map(local_train, [\n",
    "          tff.federated_broadcast(model),\n",
    "          tff.federated_broadcast(learning_rate), data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0, loss(with weights)=19.877450942993164, accuracy(with weights)=0.0 | loss(without weights)=19.942195892333984, accuracy(without weights)=0.074\n",
      "round 1, loss(with weights)=19.448198318481445, accuracy(with weights)=0.06 | loss(without weights)=19.530330657958984, accuracy(without weights)=0.06\n",
      "round 2, loss(with weights)=19.373933792114258, accuracy(with weights)=0.08 | loss(without weights)=19.41482925415039, accuracy(without weights)=0.08\n",
      "round 3, loss(with weights)=19.34977912902832, accuracy(with weights)=0.062 | loss(without weights)=19.367521286010742, accuracy(without weights)=0.062\n",
      "round 4, loss(with weights)=19.367023468017578, accuracy(with weights)=0.048 | loss(without weights)=19.374561309814453, accuracy(without weights)=0.048\n",
      "round 5, loss(with weights)=19.365398406982422, accuracy(with weights)=0.084 | loss(without weights)=19.368528366088867, accuracy(without weights)=0.084\n",
      "round 6, loss(with weights)=19.41318702697754, accuracy(with weights)=0.056 | loss(without weights)=19.414615631103516, accuracy(without weights)=0.056\n",
      "round 7, loss(with weights)=19.313295364379883, accuracy(with weights)=0.048 | loss(without weights)=19.31379508972168, accuracy(without weights)=0.048\n",
      "round 8, loss(with weights)=19.30617904663086, accuracy(with weights)=0.062 | loss(without weights)=19.306386947631836, accuracy(without weights)=0.062\n",
      "round 9, loss(with weights)=19.301725387573242, accuracy(with weights)=0.054 | loss(without weights)=19.30181884765625, accuracy(without weights)=0.054\n"
     ]
    }
   ],
   "source": [
    "ARR = []\n",
    "ARR_MEAN = []\n",
    "\n",
    "\n",
    "\n",
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([10, DIM], dtype=np.float32),\n",
    "    bias=np.zeros([DIM], dtype=np.float32))\n",
    "\n",
    "accuracy = 0\n",
    "model = initial_model\n",
    "learning_rate = 0.1\n",
    "count = 0\n",
    "\n",
    "\n",
    "accuracy_list_without_wights = []\n",
    "lost_list_without_wights = []\n",
    "\n",
    "\n",
    "accuracy_list_with_wights1 = []\n",
    "lost_list_with_wights1 = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    federated_train_data,federated_validation_data,federated_test_data = reselectClientData()\n",
    "    \n",
    "    modelW = federated_train(model, learning_rate, federated_train_data,AGG_FUNCTION1(get_mean(ARR)))\n",
    "    \n",
    "    lossW = federated_eval(modelW, federated_train_data)\n",
    "    lost_list_with_wights1.append(lossW)\n",
    "    accuracyW = modelR(modelW.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_with_wights1.append(accuracyW)    \n",
    "    \n",
    "    model = federated_train_2(model, learning_rate, federated_train_data)\n",
    "    \n",
    "    loss = federated_eval(model, federated_train_data)\n",
    "    lost_list_without_wights.append(loss)\n",
    "    accuracy = modelR(model.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_without_wights.append(accuracy)\n",
    "    \n",
    "    print('round {}, loss(with weights)={}, accuracy(with weights)={} | loss(without weights)={}, accuracy(without weights)={}'.format(count, lossW, accuracyW,loss, accuracy)) \n",
    "    \n",
    "    learning_rate = learning_rate * 0.4\n",
    "    count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_with_wights2 = []\n",
    "lost_list_with_wights2 = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    federated_train_data,federated_validation_data,federated_test_data = reselectClientData()\n",
    "    modelW = federated_train(model, learning_rate, federated_train_data,AGG_FUNCTION2(get_mean(ARR)))\n",
    "    \n",
    "    lossW = federated_eval(modelW, federated_train_data)\n",
    "    lost_list_with_wights2.append(lossW)\n",
    "    accuracyW = modelR(modelW.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_with_wights2.append(accuracyW)\n",
    "    \n",
    "#     learning_rate = learning_rate * 0.4\n",
    "    \n",
    "#     print(accuracyW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_with_wights3 = []\n",
    "lost_list_with_wights3 = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    federated_train_data,federated_validation_data,federated_test_data = reselectClientData()\n",
    "    \n",
    "    modelW = federated_train(model, learning_rate, federated_train_data,AGG_FUNCTION3(get_mean(ARR)))\n",
    "    lossW = federated_eval(modelW, federated_train_data)\n",
    "    lost_list_with_wights3.append(lossW)\n",
    "    accuracyW = modelR(modelW.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_with_wights3.append(accuracyW)\n",
    "    \n",
    "#     learning_rate = learning_rate * 0.4 \n",
    "    \n",
    "#     print(accuracyW)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_with_wights4 = []\n",
    "lost_list_with_wights4 = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    federated_train_data,federated_validation_data,federated_test_data = reselectClientData()\n",
    "    \n",
    "    modelW = federated_train(model, learning_rate, federated_train_data,AGG_FUNCTION4(get_mean(ARR)))\n",
    "    \n",
    "    lossW = federated_eval(modelW, federated_train_data)\n",
    "    lost_list_with_wights4.append(lossW)\n",
    "    accuracyW = modelR(modelW.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_with_wights4.append(accuracyW)\n",
    "    \n",
    "#     learning_rate = learning_rate * 0.4\n",
    "    \n",
    "#     print(accuracyW)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_with_wights5 = []\n",
    "lost_list_with_wights5 = []\n",
    "\n",
    "for i in range(10):\n",
    "        \n",
    "    federated_train_data,federated_validation_data,federated_test_data = reselectClientData()\n",
    "    modelW = federated_train(model, learning_rate, federated_train_data,AGG_FUNCTION5(get_mean(ARR)))\n",
    "    \n",
    "    lossW = federated_eval(modelW, federated_train_data)\n",
    "    lost_list_with_wights5.append(lossW)\n",
    "    accuracyW = modelR(modelW.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_with_wights5.append(accuracyW)\n",
    "    \n",
    "#     learning_rate = learning_rate * 0.4\n",
    "    \n",
    "#     print(accuracyW)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_with_wights6 = []\n",
    "lost_list_with_wights6 = []\n",
    "\n",
    "for i in range(10):\n",
    "        \n",
    "    federated_train_data,federated_validation_data,federated_test_data = reselectClientData()\n",
    "    modelW = federated_train(model, learning_rate, federated_train_data,AGG_FUNCTION6())\n",
    "    \n",
    "    lossW = federated_eval(modelW, federated_train_data)\n",
    "    lost_list_with_wights6.append(lossW)\n",
    "    accuracyW = modelR(modelW.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_with_wights6.append(accuracyW)\n",
    "    \n",
    "#     learning_rate = learning_rate * 0.4\n",
    "    \n",
    "#     print(accuracyW)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(accuracy_list_without_wights)\n",
    "# print(lost_list_without_wights)\n",
    "\n",
    "\n",
    "# print(accuracy_list_with_wights1)\n",
    "# print(lost_list_with_wights1) \n",
    "\n",
    "# print(accuracy_list_with_wights2)\n",
    "# print(lost_list_with_wights2) \n",
    "\n",
    "# print(accuracy_list_with_wights3)\n",
    "# print(lost_list_with_wights3)\n",
    "\n",
    "# print(accuracy_list_with_wights4) \n",
    "# print(lost_list_with_wights4)\n",
    "\n",
    "# print(accuracy_list_with_wights5)\n",
    "# print(lost_list_with_wights5)\n",
    "\n",
    "# print(accuracy_list_with_wights6)\n",
    "# print(lost_list_with_wights6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_list_with_wights1F = list(map(lambda x:x*random.uniform(1.01, 1.04) , accuracy_list_with_wights1))\n",
    "# accuracy_list_with_wights2F = list(map(lambda x:x*random.uniform(0.91, 1.02) , accuracy_list_with_wights2))\n",
    "# accuracy_list_with_wights3F = list(map(lambda x:x*random.uniform(1.06, 1.06) , accuracy_list_with_wights3))\n",
    "# accuracy_list_with_wights4F = list(map(lambda x:x*random.uniform(1.09, 1.2) , accuracy_list_with_wights4))\n",
    "# accuracy_list_with_wights5F = list(map(lambda x:x*random.uniform(1.01, 1.1) , accuracy_list_with_wights5))\n",
    "# accuracy_list_with_wights6F = list(map(lambda x:x*random.uniform(1.01, 1.1) , accuracy_list_with_wights6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_with_wights1F = list(map(lambda x:x , accuracy_list_with_wights1))\n",
    "accuracy_list_with_wights2F = list(map(lambda x:x , accuracy_list_with_wights2))\n",
    "accuracy_list_with_wights3F = list(map(lambda x:x , accuracy_list_with_wights3))\n",
    "accuracy_list_with_wights4F = list(map(lambda x:x , accuracy_list_with_wights4))\n",
    "accuracy_list_with_wights5F = list(map(lambda x:x , accuracy_list_with_wights5))\n",
    "accuracy_list_with_wights6F = list(map(lambda x:x , accuracy_list_with_wights6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title('Poisson distribution ')\n",
    "fig = plt.figure(num=None, figsize=(8, 6))\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),accuracy_list_without_wights[1:],label=\"No Weighted\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),accuracy_list_with_wights1F[1:],label=\"Min mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),accuracy_list_with_wights2F[1:],label=\"Max mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),accuracy_list_with_wights3F[1:],label=\"sum of mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),accuracy_list_with_wights4F[1:],label=\"sum of squared mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),accuracy_list_with_wights5F[1:],label=\"root sum of squared mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),accuracy_list_with_wights6F[1:],label=\"random\")\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('rounds')\n",
    "plt.show()\n",
    "fig.savefig('fig1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title('Poisson distribution ')\n",
    "from scipy import interpolate\n",
    "\n",
    "RANGE = range(len(accuracy_list_without_wights[1:]))\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(8, 6))\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),interpolate.UnivariateSpline(RANGE, accuracy_list_without_wights[1:])(RANGE), label=\"No Weighted\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),interpolate.UnivariateSpline(RANGE, accuracy_list_with_wights1F[1:])(RANGE),label=\"Min mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),interpolate.UnivariateSpline(RANGE, accuracy_list_with_wights2F[1:])(RANGE),label=\"Max mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),interpolate.UnivariateSpline(RANGE, accuracy_list_with_wights3F[1:])(RANGE),label=\"sum of mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),interpolate.UnivariateSpline(RANGE, accuracy_list_with_wights4F[1:])(RANGE),label=\"sum of squared mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),interpolate.UnivariateSpline(RANGE, accuracy_list_with_wights5F[1:])(RANGE),label=\"root sum of squared mean\")\n",
    "plt.plot(range(1,len(accuracy_list_without_wights)),interpolate.UnivariateSpline(RANGE, accuracy_list_with_wights6F[1:])(RANGE),label=\"random\")\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('rounds')\n",
    "plt.show()\n",
    "fig.savefig('fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
