{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random \n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import nest_asyncio\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "sns.set_theme(style= 'whitegrid')\n",
    "nest_asyncio.apply()\n",
    "tff.backends.reference.set_reference_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import sklearn.datasets as dt\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "color_map_discrete = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"cyan\",\"magenta\",\"blue\"])\n",
    "\n",
    "x,y = dt.make_classification(n_samples=50000,\n",
    "                                 n_features=2,\n",
    "                                 n_repeated=0,\n",
    "                                 class_sep=2,\n",
    "                                 n_redundant=0,\n",
    "                                 n_classes=3,\n",
    "                                 n_clusters_per_class=1,\n",
    "                                 random_state=2000)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "my_scatter_plot = plt.scatter(x[:,0],\n",
    "                                  x[:,1],\n",
    "                                  c=y,\n",
    "                                  vmin=min(y),\n",
    "                                  vmax=max(y),\n",
    "                                  s=5,\n",
    "                                  cmap=color_map_discrete)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "list0 = []\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for a,b in zip(x,y):\n",
    "    c = a.tolist()\n",
    "    c.append(b)\n",
    "    if b == 0:\n",
    "        list0.append(c)\n",
    "    elif b == 1:\n",
    "        list1.append(c)\n",
    "    else:\n",
    "        list2.append(c)\n",
    "\n",
    "client1 = []\n",
    "client2 = []\n",
    "client3 = []\n",
    "\n",
    "l01 = math.ceil(len(list0)*0.7)\n",
    "l02 = math.ceil(len(list0)*0.8)\n",
    "\n",
    "l11 = math.ceil(len(list0)*0.6)\n",
    "l12 = math.ceil(len(list0)*0.75)\n",
    "\n",
    "l21 = math.ceil(len(list0)*0.65)\n",
    "l22 = math.ceil(len(list0)*0.85)\n",
    "\n",
    "\n",
    "CLIENT1 = list0[:l01] + list1[l11:l12] + list2[l22:]\n",
    "CLIENT2 = list0[l02:] + list1[:l11] + list2[l21:l22]\n",
    "CLIENT3 = list0[l01:l02] + list1[l12:] + list2[:l21]\n",
    "\n",
    "random.shuffle(client1)\n",
    "random.shuffle(client2)\n",
    "random.shuffle(client3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARR = []\n",
    "ARR_MEAN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(HOLDER):\n",
    "    federated_data = []\n",
    "    for i in HOLDER:\n",
    "        client = []\n",
    "        for index in range(len(i)//100):\n",
    "            X= []\n",
    "            Y= []\n",
    "            for elements in i[index*100:index*100+100]:\n",
    "                X.append(np.array([np.float32(elements[0]),np.float32(elements[1])]))\n",
    "                Y.append(np.array(np.int32(elements[2])))\n",
    "            client.append({\n",
    "                'x':np.array(X),\n",
    "                'y':np.array(Y)\n",
    "            })\n",
    "        federated_data.append(client)\n",
    "    return federated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poissonDistributiondata(clientData):\n",
    "    data = random.sample(clientData,2000)\n",
    "    return [data[:1000],data[1000:1500],data[1500:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reselectClientData():\n",
    "    c1_tra, c1_val, c1_test = poissonDistributiondata(CLIENT1)\n",
    "    c2_tra, c2_val, c2_test = poissonDistributiondata(CLIENT2)\n",
    "    c3_tra, c3_val, c3_test = poissonDistributiondata(CLIENT3)\n",
    "\n",
    "    train = [c1_tra,   c2_tra,  c3_tra]\n",
    "    val   = [c1_val,   c2_val,  c3_val]\n",
    "    test  = [c1_test, c2_test, c3_test]\n",
    "\n",
    "    federated_train_data      =  get_batches(train)\n",
    "    federated_validation_data =  get_batches(val)\n",
    "    federated_test_data       =  get_batches(test)\n",
    "    \n",
    "    #count\n",
    "    ARR.append([Counter(list(map(lambda x: x[-1], c1_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c2_tra))), \n",
    "                Counter(list(map(lambda x: x[-1], c3_tra)))])\n",
    "    #mean\n",
    "    \n",
    "    return (federated_train_data,federated_validation_data,federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(arr_history):\n",
    "    client1_means = [i[0] for i in arr_history]\n",
    "    client2_means = [i[1] for i in arr_history]\n",
    "    client3_means = [i[2] for i in arr_history]\n",
    "    \n",
    "    client1_means_vals_c1 = [i.get(0) for i in client1_means]\n",
    "    client1_means_vals_c2 = [i.get(1) for i in client1_means]    \n",
    "    client1_means_vals_c3 = [i.get(2) for i in client1_means]    \n",
    "    \n",
    "    client2_means_vals_c1 = [i.get(0) for i in client2_means]\n",
    "    client2_means_vals_c2 = [i.get(1) for i in client2_means]    \n",
    "    client2_means_vals_c3 = [i.get(2) for i in client2_means] \n",
    "    \n",
    "    client3_means_vals_c1 = [i.get(0) for i in client3_means]\n",
    "    client3_means_vals_c2 = [i.get(1) for i in client3_means]    \n",
    "    client3_means_vals_c3 = [i.get(2) for i in client3_means]  \n",
    "    \n",
    "    return {\n",
    "        'client1':{\n",
    "            0: mean(client1_means_vals_c1),\n",
    "            1: mean(client1_means_vals_c2),\n",
    "            2: mean(client1_means_vals_c3)\n",
    "        },\n",
    "        'client2':{\n",
    "            0: mean(client2_means_vals_c1),\n",
    "            1: mean(client2_means_vals_c2),\n",
    "            2: mean(client2_means_vals_c3)\n",
    "        },\n",
    "        'client3':{\n",
    "            0: mean(client3_means_vals_c1),\n",
    "            1: mean(client3_means_vals_c2),\n",
    "            2: mean(client3_means_vals_c3)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Follow shows the get mean output\n",
    "```get_mean(ARR)```\n",
    "\n",
    "```{'client1': {0: 706.5, 1: 154, 2: 139.5},\n",
    " 'client2': {0: 188, 1: 611, 2: 201},\n",
    " 'client3': {0: 92, 1: 245, 2: 663}}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom mean aggregation function goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGG_FUNCTION1(mean):\n",
    "    return [\n",
    "        np.float32(max(mean.get('client1').values())),\n",
    "        np.float32(max(mean.get('client2').values())),\n",
    "        np.float32(max(mean.get('client3').values()))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Data Types [Client and Server]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(x=tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n",
    "                                     y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "\n",
    "MODEL_SPEC = collections.OrderedDict(weights=tf.TensorSpec(shape=[2, 3], dtype=tf.float32),\n",
    "                                     bias=tf.TensorSpec(shape=[3], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "\n",
    "WEIGHT_SPEC = tff.TensorType(dtype=tf.float32, shape=None)\n",
    "WEIGHT_TYPE = tff.to_type(WEIGHT_SPEC)\n",
    "WEIGHT_DATA_TYPE = tff.FederatedType(WEIGHT_TYPE, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(tf.reduce_sum(tf.one_hot(batch['y'], 3) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "    return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model_vars, batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "  \n",
    "    return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_fn(model, batch):\n",
    "        return batch_train(model, batch, learning_rate)\n",
    "    return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "    return tff.sequence_sum(tff.sequence_map(tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),all_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.type_at_server(MODEL_TYPE)\n",
    "CLIENT_DATA_TYPE = tff.type_at_clients(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "    return tff.federated_mean(tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SERVER_FLOAT_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.type_at_server(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With custom weighting factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,CLIENT_DATA_TYPE, WEIGHT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data, weights):\n",
    "    return tff.federated_mean(\n",
    "          tff.federated_map(local_train, [\n",
    "          tff.federated_broadcast(model),\n",
    "          tff.federated_broadcast(learning_rate), data]), weights)\n",
    "\n",
    "def modelR(weights, biases, data):\n",
    "    count = 0\n",
    "    avg = 0\n",
    "    for j in range(len(federated_test_data[0])):\n",
    "        l = [np.where(i==max(i))[0][0] for i in activations.sigmoid(np.matmul(federated_test_data[0][j].get('x'), model.get('weights'))).numpy()]\n",
    "        Y = federated_test_data[0][j].get('y')\n",
    "        \n",
    "        for i in range(len(Y)):\n",
    "            avg+=1\n",
    "            if l[i] == Y[i]:\n",
    "                count+= 1\n",
    "                \n",
    "    return count/avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without custom weighting factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,CLIENT_DATA_TYPE)\n",
    "def federated_train_2(model, learning_rate, data):\n",
    "    return tff.federated_mean(\n",
    "          tff.federated_map(local_train, [\n",
    "          tff.federated_broadcast(model),\n",
    "          tff.federated_broadcast(learning_rate), data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([2, 3], dtype=np.float32),\n",
    "    bias=np.zeros([3], dtype=np.float32))\n",
    "\n",
    "accuracy = 0\n",
    "model = initial_model\n",
    "learning_rate = 0.1\n",
    "count = 0\n",
    "\n",
    "\n",
    "\n",
    "accuracy_list_with_wights = []\n",
    "accuracy_list_without_wights = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    federated_train_data,federated_validation_data,federated_test_data = reselectClientData()\n",
    "    \n",
    "    modelW = federated_train(model, learning_rate, federated_train_data,AGG_FUNCTION1(get_mean(ARR)))\n",
    "    \n",
    "    learning_rateW = learning_rateW * 0.9\n",
    "    lossW = federated_eval(modelW, federated_train_data)\n",
    "    accuracyW = modelR(modelW.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_with_wights.append(accuracyW)\n",
    "    \n",
    "    \n",
    "    model = federated_train_2(model, learning_rate, federated_train_data)\n",
    "    \n",
    "    learning_rate = learning_rate * 0.9\n",
    "    loss = federated_eval(model, federated_train_data)\n",
    "    accuracy = modelR(model.get('weights'), model.get('bias'), federated_test_data)\n",
    "    accuracy_list_without_wights.append(accuracy)\n",
    "    \n",
    "    print('round {}, loss(with weights)={}, accuracy(with weights)={} | loss(without weights)={}, accuracy(without weights)={}'.format(count, lossW, accuracyW,loss, accuracy)) \n",
    "    \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def createDF(arr):\n",
    "    client1 = [i[0] for i in arr]\n",
    "    client2 = [i[1] for i in arr]\n",
    "    client3 = [i[2] for i in arr]\n",
    "    return (pd.DataFrame(client1),pd.DataFrame(client2),pd.DataFrame(client3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1,c2,c3 = createDF(ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=(10,3))\n",
    "ax1 =plt.subplot(1, 3, 1,)\n",
    "ax1.set_title('class 0')\n",
    "ax1.tick_params(labelrotation=90)\n",
    "\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c1[0])\n",
    "ax1.bar(langs,count)\n",
    "\n",
    "ax2 =plt.subplot(1, 3, 2)\n",
    "ax2.set_title('class 1')\n",
    "ax2.tick_params(labelrotation=90)\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c1[1])\n",
    "ax2.bar(langs,count)\n",
    "\n",
    "ax3 =plt.subplot(1, 3, 3)\n",
    "ax3.set_title('class 2')\n",
    "ax3.tick_params(labelrotation=90)\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c1[2])\n",
    "ax3.bar(langs,count)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=(10,3))\n",
    "ax1 =plt.subplot(1, 3, 1,)\n",
    "ax1.set_title('class 0')\n",
    "ax1.tick_params(labelrotation=90)\n",
    "\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c2[0])\n",
    "ax1.bar(langs,count)\n",
    "\n",
    "ax2 =plt.subplot(1, 3, 2)\n",
    "ax2.set_title('class 1')\n",
    "ax2.tick_params(labelrotation=90)\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c2[1])\n",
    "ax2.bar(langs,count)\n",
    "\n",
    "ax3 =plt.subplot(1, 3, 3)\n",
    "ax3.set_title('class 2')\n",
    "ax3.tick_params(labelrotation=90)\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c2[2])\n",
    "ax3.bar(langs,count)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=(10,3))\n",
    "ax1 =plt.subplot(1, 3, 1,)\n",
    "ax1.set_title('class 0')\n",
    "ax1.tick_params(labelrotation=90)\n",
    "\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c3[0])\n",
    "ax1.bar(langs,count)\n",
    "\n",
    "ax2 =plt.subplot(1, 3, 2)\n",
    "ax2.set_title('class 1')\n",
    "ax2.tick_params(labelrotation=90)\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c3[1])\n",
    "ax2.bar(langs,count)\n",
    "\n",
    "ax3 =plt.subplot(1, 3, 3)\n",
    "ax3.set_title('class 2')\n",
    "ax3.tick_params(labelrotation=90)\n",
    "langs = ['round {}'.format(i) for i in range(1,len(c1)+1)]\n",
    "count = list(c3[2])\n",
    "ax3.bar(langs,count)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
