{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "!pip install --quiet --upgrade tensorflow_federated_nightly\n",
    "!pip install --quiet --upgrade nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "# import pickle\n",
    "\n",
    "tff.backends.reference.set_reference_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A federated type BATCH_TYPE is defined to use as the type of a single batch of data in a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A federated type MODEL_TYPE is defined to use as the type of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weights=float32[784,10],bias=float32[10]>\n"
     ]
    }
   ],
   "source": [
    "MODEL_SPEC = collections.OrderedDict(\n",
    "    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
    "    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "print(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loss function is made such that it gives the loss for a given model over a single batch.\n",
    "forward_pass is defined as a seperate function so that we cna use it individually inside a method with the decorator @tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "    return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent on a single batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model_vars, batch):\n",
    "        # Perform one step of gradient descent using loss from `batch_loss`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "  \n",
    "    return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent on a single client (of all batches of one client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "    \n",
    "    # Mapping function to apply to each batch.\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_fn(model, batch):\n",
    "        return batch_train(model, batch, learning_rate)\n",
    "    return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local evaluation is done by adding the up the losses across all data batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "    return tff.sequence_sum(\n",
    "        tff.sequence_map(\n",
    "            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),all_batches))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
