{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "5Cwi_q7-cvRq",
    "outputId": "31b79de0-60c7-4c57-f533-00809deb9593"
   },
   "outputs": [],
   "source": [
    "# #@test {\"skip\": true}\n",
    "# !pip install --quiet --upgrade tensorflow_federated_nightly\n",
    "# !pip install --quiet --upgrade nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "MKiQHmO2cw7L",
    "outputId": "569a0f97-77f6-4953-bc02-87a70ec923fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deravindusilva/anaconda3/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210101). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tff.backends.reference.set_reference_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VX4809PmzpP3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "u5VvdCXQczgF",
    "outputId": "6a8ad180-8222-478a-dc19-75cf20f12dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6XyZsp1Ic2U7",
    "outputId": "07f40770-2269-49d8-c9ba-906f41a78c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.dtype, x.shape) for x in mnist_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_USER = 1000\n",
    "BATCH_SIZE = 100\n",
    "NUM_OF_CLIENTS = 90\n",
    "# NUM_OF_CLIENTS_ARRAY = [0,0,0,0, 1,1,1,1, 2,2,2,2, 3,3,3,3, 4,4,4,4, 5,5,5,5, 6,6,6,6, 7,7,7,7, 8,8,8,8, 9,9,9,9]\n",
    "# NUM_OF_CLIENTS_ARRAY = [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_X, source_train_Y = shuffle(mnist_train[0], mnist_train[1], random_state=0)\n",
    "source_test_X, source_test_Y = shuffle(mnist_test[0], mnist_test[1], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_digit_iid(source_X, source_Y):\n",
    "    output_sequence = []\n",
    "    for i in range(0, min(NUM_EXAMPLES_PER_USER, len(source_X)), BATCH_SIZE):\n",
    "        batch_samples_X = source_X[i:i + BATCH_SIZE]\n",
    "        batch_samples_Y = source_Y[i:i + BATCH_SIZE]\n",
    "        output_sequence.append({\n",
    "            'x': np.array([xx.flatten() / 255.0 for xx in batch_samples_X],dtype=np.float32),\n",
    "            'y': np.array([yy for yy in batch_samples_Y], dtype=np.int32)\n",
    "        })\n",
    "    return output_sequence\n",
    "\n",
    "xtr = int(len(source_train_X)/NUM_OF_CLIENTS)\n",
    "ytr = int(len(source_train_Y)/NUM_OF_CLIENTS)\n",
    "\n",
    "xte = int(len(source_test_X)/NUM_OF_CLIENTS)\n",
    "yte = int(len(source_test_Y)/NUM_OF_CLIENTS)\n",
    "\n",
    "federated_train_data = [get_data_for_digit_iid(source_train_X[(d*xtr):(d*xtr+xtr)], source_train_Y[(d*ytr):(d*ytr+ytr)]) for d in range(NUM_OF_CLIENTS)]\n",
    "\n",
    "federated_test_data = [get_data_for_digit_iid(source_test_X[(d*xte):(d*xte+xte)], source_test_Y[(d*yte):(d*yte+yte)]) for d in range(NUM_OF_CLIENTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nrTiHne0c4ge"
   },
   "outputs": [],
   "source": [
    "def get_data_for_digit_niid(source, digit):\n",
    "    output_sequence = []\n",
    "    all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
    "    for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
    "        batch_samples = all_samples[i:i + BATCH_SIZE]\n",
    "        output_sequence.append({\n",
    "            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],dtype=np.float32),\n",
    "            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)\n",
    "        })\n",
    "    return output_sequence\n",
    "\n",
    "\n",
    "# federated_train_data = [get_data_for_digit_niid(mnist_train, d) for d in NUM_OF_CLIENTS_ARRAY]\n",
    "\n",
    "# federated_test_data = [get_data_for_digit_iid(source_test_X[(d*xte):(d*xte+xte)], source_test_Y[(d*yte):(d*yte+yte)]) for d in range(NUM_OF_CLIENTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data[0][0].get('y').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data2[0][0].get('x').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data2[0][0].get('y').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h11ZVPzqc7fP",
    "outputId": "609e2b6f-eaf2-457a-f17e-47e7003dc4d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2Yb_1Osvc-Ew",
    "outputId": "a245b92d-18c7-434b-8283-382573c7555d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>*'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "str(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zrmwNaeHdASz",
    "outputId": "562a6c0b-6455-4723-cf52-7a4bf17371b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weights=float32[784,10],bias=float32[10]>\n"
     ]
    }
   ],
   "source": [
    "MODEL_SPEC = collections.OrderedDict(\n",
    "    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
    "    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "print(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IRsjqo28dCWM"
   },
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
    "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYF50QRoezB8"
   },
   "source": [
    "Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "zlAbOvKLeJ2B",
    "outputId": "65a0fcfc-4298-4f5e-c496-0679378740f5"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "    return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RZIhjTNQeKYE"
   },
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model_vars, batch):\n",
    "        # Perform one step of gradient descent using loss from `batch_loss`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "  \n",
    "    return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sdq76fTteNp_"
   },
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "    \n",
    "    # Mapping function to apply to each batch.\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_fn(model, batch):\n",
    "        return batch_train(model, batch, learning_rate)\n",
    "    return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7Xr1aC3ueQoh"
   },
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "    return tff.sequence_sum(\n",
    "        tff.sequence_map(\n",
    "            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),all_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBusRTkOecjz"
   },
   "source": [
    "Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "d8refcNTedxR"
   },
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "    return tff.federated_mean(tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tZCrb9S5ee1w"
   },
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
    "\n",
    "\n",
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n",
    "                           CLIENT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data):\n",
    "#     client_output = tff.federated_map(local_train, [\n",
    "#             tff.federated_broadcast(model),\n",
    "#              tff.federated_broadcast(learning_rate), data\n",
    "#         ])\n",
    "    return tff.federated_mean(tff.federated_map(local_train, [\n",
    "            tff.federated_broadcast(model),\n",
    "             tff.federated_broadcast(learning_rate), data\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dJO2nd7oehym"
   },
   "outputs": [],
   "source": [
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([784, 10], dtype=np.float32),\n",
    "    bias=np.zeros([10], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UFMhiS-48Nab"
   },
   "outputs": [],
   "source": [
    "def modelR(weights, biases, data):\n",
    "  count = 0\n",
    "  avg = 0\n",
    "  for j in range(len(federated_test_data[0])):\n",
    "    l = [np.where(i==max(i))[0][0] for i in activations.sigmoid(np.matmul(federated_test_data[0][j].get('x'), model.get('weights'))).numpy()]\n",
    "    Y = federated_test_data[0][j].get('y')\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "      avg+=1\n",
    "      if l[i] == Y[i]:\n",
    "        count+= 1\n",
    "  return count/avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "K255_UxaemO8",
    "outputId": "7558bc97-0593-4ec0-afd4-6759f13ddd23"
   },
   "outputs": [],
   "source": [
    "# model = initial_model\n",
    "# learning_rate = 0.1\n",
    "# for round_num in range(5):\n",
    "#     model = federated_train(model, learning_rate, federated_train_data)\n",
    "#     learning_rate = learning_rate * 0.9\n",
    "#     loss = federated_eval(model, federated_train_data)\n",
    "#     print('round {}, loss={}, accuracy={}'.format(round_num, loss, modelR(model.get('weights'), model.get('bias'), federated_test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1, loss=12.019745826721191, accuracy=0.7837837837837838\n",
      "round 2, loss=9.80299186706543, accuracy=0.8108108108108109\n",
      "round 3, loss=8.504426002502441, accuracy=0.8468468468468469\n",
      "round 4, loss=7.675743103027344, accuracy=0.8558558558558559\n",
      "round 5, loss=7.1082444190979, accuracy=0.8558558558558559\n",
      "round 6, loss=6.698227405548096, accuracy=0.8558558558558559\n",
      "round 7, loss=6.38978385925293, accuracy=0.8648648648648649\n",
      "round 8, loss=6.150468826293945, accuracy=0.8648648648648649\n",
      "round 9, loss=5.960265636444092, accuracy=0.8648648648648649\n",
      "round 10, loss=5.806177616119385, accuracy=0.8558558558558559\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "model = initial_model\n",
    "learning_rate = 0.1\n",
    "count = 0\n",
    "\n",
    "accuracy_list = []\n",
    "for i in range(10):\n",
    "    model = federated_train(model, learning_rate, federated_train_data)\n",
    "    learning_rate = learning_rate * 0.9\n",
    "    loss = federated_eval(model, federated_train_data)\n",
    "    accuracy = modelR(model.get('weights'), model.get('bias'), federated_test_data)\n",
    "    count+=1\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('round {}, loss={}, accuracy={}'.format(count, loss, accuracy)) \n",
    "\n",
    "pickle.dump(accuracy_list, open('90_clients', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '20_clients'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-db5682715bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20_clients'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"20\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'30_clients'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"30\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'50_clients'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"50\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'90_clients'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"90\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '20_clients'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(pickle.load(open('20_clients', 'rb')), label=\"20\")\n",
    "plt.plot(pickle.load(open('30_clients', 'rb')), label=\"30\")\n",
    "plt.plot(pickle.load(open('50_clients', 'rb')), label=\"50\")\n",
    "plt.plot(pickle.load(open('90_clients', 'rb')), label=\"90\")\n",
    "\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmPjZSxFvCqM"
   },
   "outputs": [],
   "source": [
    "# def modelR(weights, biases, data):\n",
    "#   count = 0\n",
    "#   avg = 0\n",
    "#   for j in range(len(federated_test_data[0])):\n",
    "#     l = [np.where(i==max(i))[0][0] for i in activations.sigmoid(np.matmul(federated_test_data[0][j].get('x'), model.get('weights'))).numpy()]\n",
    "#     Y = federated_test_data[0][j].get('y')\n",
    "#     print('l={}, Y={}'.format(l, Y))\n",
    "    \n",
    "#     for i in range(len(Y)):\n",
    "#       avg+=1\n",
    "#       if l[i] == Y[i]:\n",
    "#         count+= 1\n",
    "#   return count/avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHun6SBbvJCF"
   },
   "outputs": [],
   "source": [
    "# modelR(model.get('weights'), model.get('bias'), federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'y': array([8, 7, 1, 7, 1, 2, 1, 9, 5, 4, 5, 6, 3, 2, 0, 7, 6, 4, 6, 4, 5, 7,\n",
       "        8, 9, 8, 7, 4, 3, 9, 4, 2, 2, 9, 7, 6, 7, 1, 2, 8, 3, 0, 6, 4, 0,\n",
       "        8, 7, 8, 2, 9, 0, 4, 3, 4, 0, 7, 0, 7, 4, 6, 1, 9, 7, 2, 8, 8, 0,\n",
       "        1, 0, 5, 1, 5, 1, 4, 9, 4, 8, 7, 3, 7, 8, 9, 1, 4, 4, 0, 2, 5, 7,\n",
       "        7, 5, 3, 0, 6, 2, 4, 1, 6, 8, 6, 9], dtype=int32)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FL Test",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
