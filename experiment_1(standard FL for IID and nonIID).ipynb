{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "5Cwi_q7-cvRq",
    "outputId": "31b79de0-60c7-4c57-f533-00809deb9593"
   },
   "outputs": [],
   "source": [
    "# #@test {\"skip\": true}\n",
    "# !pip install --quiet --upgrade tensorflow_federated_nightly\n",
    "# !pip install --quiet --upgrade nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "MKiQHmO2cw7L",
    "outputId": "569a0f97-77f6-4953-bc02-87a70ec923fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dns_cluster_2_gmail_com/anaconda3/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.4.0-dev20201019). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tff.backends.reference.set_reference_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VX4809PmzpP3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "u5VvdCXQczgF",
    "outputId": "6a8ad180-8222-478a-dc19-75cf20f12dfb"
   },
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6XyZsp1Ic2U7",
    "outputId": "07f40770-2269-49d8-c9ba-906f41a78c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.dtype, x.shape) for x in mnist_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_USER = 1000\n",
    "BATCH_SIZE = 1000\n",
    "NUM_OF_CLIENTS = 90\n",
    "# NUM_OF_CLIENTS_ARRAY = [0,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1,1, 2,2,2,2,2,2,2,2,2, 3,3,3,3,3,3,3,3,3, 4,4,4,4,4,4,4,4,4, 5,5,5,5,5,5,5,5,5, 6,6,6,6,6,6,6,6,6, 7,7,7,7,7,7,7,7,7, 8,8,8,8,8,8,8,8,8, 9,9,9,9,9,9,9,9,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_X, source_train_Y = shuffle(mnist_train[0], mnist_train[1], random_state=0)\n",
    "source_test_X, source_test_Y = shuffle(mnist_test[0], mnist_test[1], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_digit_iid(source_X, source_Y):\n",
    "    output_sequence = []\n",
    "    for i in range(0, min(NUM_EXAMPLES_PER_USER, len(source_X)), BATCH_SIZE):\n",
    "        batch_samples_X = source_X[i:i + BATCH_SIZE]\n",
    "        batch_samples_Y = source_Y[i:i + BATCH_SIZE]\n",
    "        output_sequence.append({\n",
    "            'x': np.array([xx.flatten() / 255.0 for xx in batch_samples_X],dtype=np.float32),\n",
    "            'y': np.array([yy for yy in batch_samples_Y], dtype=np.int32)\n",
    "        })\n",
    "    return output_sequence\n",
    "\n",
    "xtr = int(len(source_train_X)/NUM_OF_CLIENTS)\n",
    "ytr = int(len(source_train_Y)/NUM_OF_CLIENTS)\n",
    "\n",
    "xte = int(len(source_test_X)/NUM_OF_CLIENTS)\n",
    "yte = int(len(source_test_Y)/NUM_OF_CLIENTS)\n",
    "\n",
    "federated_train_data = [get_data_for_digit_iid(source_train_X[(d*xtr):(d*xtr+xtr)], source_train_Y[(d*ytr):(d*ytr+ytr)]) for d in range(NUM_OF_CLIENTS)]\n",
    "\n",
    "federated_test_data = [get_data_for_digit_iid(source_test_X[(d*xte):(d*xte+xte)], source_test_Y[(d*yte):(d*yte+yte)]) for d in range(NUM_OF_CLIENTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nrTiHne0c4ge"
   },
   "outputs": [],
   "source": [
    "def get_data_for_digit_niid(source, digit):\n",
    "    output_sequence = []\n",
    "    all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
    "    for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
    "        batch_samples = all_samples[i:i + BATCH_SIZE]\n",
    "        output_sequence.append({\n",
    "            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],dtype=np.float32),\n",
    "            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)\n",
    "        })\n",
    "    return output_sequence\n",
    "\n",
    "\n",
    "# federated_train_data = [get_data_for_digit_niid(mnist_train, d) for d in NUM_OF_CLIENTS_ARRAY]\n",
    "\n",
    "# federated_test_data = [get_data_for_digit_iid(source_test_X[(d*xte):(d*xte+xte)], source_test_Y[(d*yte):(d*yte+yte)]) for d in range(NUM_OF_CLIENTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data[0][0].get('y').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data2[0][0].get('x').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated_train_data2[0][0].get('y').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h11ZVPzqc7fP",
    "outputId": "609e2b6f-eaf2-457a-f17e-47e7003dc4d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2Yb_1Osvc-Ew",
    "outputId": "a245b92d-18c7-434b-8283-382573c7555d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>*'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "str(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zrmwNaeHdASz",
    "outputId": "562a6c0b-6455-4723-cf52-7a4bf17371b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weights=float32[784,10],bias=float32[10]>\n"
     ]
    }
   ],
   "source": [
    "MODEL_SPEC = collections.OrderedDict(\n",
    "    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
    "    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "print(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IRsjqo28dCWM"
   },
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
    "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYF50QRoezB8"
   },
   "source": [
    "Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "zlAbOvKLeJ2B",
    "outputId": "65a0fcfc-4298-4f5e-c496-0679378740f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function forward_pass at 0x7f2dbbd73b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function forward_pass at 0x7f2dbbd73b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "    return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RZIhjTNQeKYE"
   },
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model_vars, batch):\n",
    "        # Perform one step of gradient descent using loss from `batch_loss`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "  \n",
    "    return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sdq76fTteNp_"
   },
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "    \n",
    "    # Mapping function to apply to each batch.\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_fn(model, batch):\n",
    "        return batch_train(model, batch, learning_rate)\n",
    "    return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7Xr1aC3ueQoh"
   },
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "    return tff.sequence_sum(\n",
    "        tff.sequence_map(\n",
    "            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),all_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBusRTkOecjz"
   },
   "source": [
    "Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "d8refcNTedxR"
   },
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "    return tff.federated_mean(tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tZCrb9S5ee1w"
   },
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
    "\n",
    "\n",
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n",
    "                           CLIENT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data):\n",
    "    return tff.federated_mean(\n",
    "        tff.federated_map(local_train, [\n",
    "            tff.federated_broadcast(model),\n",
    "             tff.federated_broadcast(learning_rate), data\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dJO2nd7oehym"
   },
   "outputs": [],
   "source": [
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([784, 10], dtype=np.float32),\n",
    "    bias=np.zeros([10], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UFMhiS-48Nab"
   },
   "outputs": [],
   "source": [
    "def modelR(weights, biases, data):\n",
    "  count = 0\n",
    "  avg = 0\n",
    "  for j in range(len(federated_test_data[0])):\n",
    "    l = [np.where(i==max(i))[0][0] for i in activations.sigmoid(np.matmul(federated_test_data[0][j].get('x'), model.get('weights'))).numpy()]\n",
    "    Y = federated_test_data[0][j].get('y')\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "      avg+=1\n",
    "      if l[i] == Y[i]:\n",
    "        count+= 1\n",
    "  return count/avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "K255_UxaemO8",
    "outputId": "7558bc97-0593-4ec0-afd4-6759f13ddd23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0, loss=2.1969425678253174, accuracy=0.6936936936936937\n",
      "round 1, loss=2.110013246536255, accuracy=0.6936936936936937\n",
      "round 2, loss=2.037069082260132, accuracy=0.7117117117117117\n",
      "round 3, loss=1.9752533435821533, accuracy=0.7387387387387387\n",
      "round 4, loss=1.9225150346755981, accuracy=0.7747747747747747\n"
     ]
    }
   ],
   "source": [
    "model = initial_model\n",
    "learning_rate = 0.1\n",
    "for round_num in range(5):\n",
    "    model = federated_train(model, learning_rate, federated_train_data)\n",
    "    learning_rate = learning_rate * 0.9\n",
    "    loss = federated_eval(model, federated_train_data)\n",
    "    print('round {}, loss={}, accuracy={}'.format(round_num, loss, modelR(model.get('weights'), model.get('bias'), federated_test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cmPjZSxFvCqM"
   },
   "outputs": [],
   "source": [
    "# def modelR(weights, biases, data):\n",
    "#   count = 0\n",
    "#   avg = 0\n",
    "#   for j in range(len(federated_test_data[0])):\n",
    "#     l = [np.where(i==max(i))[0][0] for i in activations.sigmoid(np.matmul(federated_test_data[0][j].get('x'), model.get('weights'))).numpy()]\n",
    "#     Y = federated_test_data[0][j].get('y')\n",
    "#     print('l={}, Y={}'.format(l, Y))\n",
    "    \n",
    "#     for i in range(len(Y)):\n",
    "#       avg+=1\n",
    "#       if l[i] == Y[i]:\n",
    "#         count+= 1\n",
    "#   return count/avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "JHun6SBbvJCF"
   },
   "outputs": [],
   "source": [
    "# modelR(model.get('weights'), model.get('bias'), federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FL Test",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
